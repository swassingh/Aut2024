{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Fortu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Fortu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Fortu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pyterrier as pt\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "print(pt.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# document = \"\"\"Call me Ishmael. Some years ago—never mind how long precisely—having little or no money in my purse, and nothing particular to interest me on shore, I thought I would sail about a little and see the watery part of the world. It is a way I have of driving off the spleen and regulating the circulation. Whenever I find myself growing grim about the mouth; whenever it is a damp, drizzly November in my soul; whenever I find myself involuntarily pausing before coffin warehouses, and bringing up the rear of every funeral I meet; and especially whenever my hypos get such an upper hand of me, that it requires a strong moral principle to prevent me from deliberately stepping into the street, and methodically knocking people’s hats off—then, I account it high time to get to sea as soon as I can.\"\"\"\n",
    "\n",
    "document = \"It was the best of times, it was the worst of times, it was the age of wisdom, it was the age of foolishness, it was the epoch of belief, it was the epoch of incredulity, it was the season of Light, it was the season of Darkness, it was the spring of hope, it was the winter of despair\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['It was the best of times, it was the worst of times, it was the age of wisdom, it was the age of foolishness, it was the epoch of belief, it was the epoch of incredulity, it was the season of Light, it was the season of Darkness, it was the spring of hope, it was the winter of despair']\n"
     ]
    }
   ],
   "source": [
    "sentence_tokens = nltk.sent_tokenize(document)\n",
    "print(sentence_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['It', 'was', 'the', 'best', 'of', 'times', ',', 'it', 'was', 'the', 'worst', 'of', 'times', ',', 'it', 'was', 'the', 'age', 'of', 'wisdom', ',', 'it', 'was', 'the', 'age', 'of', 'foolishness', ',', 'it', 'was', 'the', 'epoch', 'of', 'belief', ',', 'it', 'was', 'the', 'epoch', 'of', 'incredulity', ',', 'it', 'was', 'the', 'season', 'of', 'Light', ',', 'it', 'was', 'the', 'season', 'of', 'Darkness', ',', 'it', 'was', 'the', 'spring', 'of', 'hope', ',', 'it', 'was', 'the', 'winter', 'of', 'despair']\n"
     ]
    }
   ],
   "source": [
    "word_tokens = nltk.word_tokenize(document)\n",
    "print(word_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['It', 'times', ',', 'worst', 'times', ',', 'age', 'wisdom', ',', 'age', 'foolishness', ',', 'epoch', 'belief', ',', 'epoch', 'incredulity', ',', 'season', 'Light', ',', 'season', 'Darkness', ',', 'spring', 'hope', ',', 'winter', 'despair']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "tokens_without_sw = [word for word in word_tokens if not word in stopwords.words()]\n",
    "print(tokens_without_sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "porter = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oroginal: It, Stem: it\n",
      "Oroginal: times, Stem: time\n",
      "Oroginal: ,, Stem: ,\n",
      "Oroginal: worst, Stem: worst\n",
      "Oroginal: times, Stem: time\n",
      "Oroginal: ,, Stem: ,\n",
      "Oroginal: age, Stem: age\n",
      "Oroginal: wisdom, Stem: wisdom\n",
      "Oroginal: ,, Stem: ,\n",
      "Oroginal: age, Stem: age\n",
      "Oroginal: foolishness, Stem: foolish\n",
      "Oroginal: ,, Stem: ,\n",
      "Oroginal: epoch, Stem: epoch\n",
      "Oroginal: belief, Stem: belief\n",
      "Oroginal: ,, Stem: ,\n",
      "Oroginal: epoch, Stem: epoch\n",
      "Oroginal: incredulity, Stem: incredul\n",
      "Oroginal: ,, Stem: ,\n",
      "Oroginal: season, Stem: season\n",
      "Oroginal: Light, Stem: light\n",
      "Oroginal: ,, Stem: ,\n",
      "Oroginal: season, Stem: season\n",
      "Oroginal: Darkness, Stem: dark\n",
      "Oroginal: ,, Stem: ,\n",
      "Oroginal: spring, Stem: spring\n",
      "Oroginal: hope, Stem: hope\n",
      "Oroginal: ,, Stem: ,\n",
      "Oroginal: winter, Stem: winter\n",
      "Oroginal: despair, Stem: despair\n",
      "['it', 'time', ',', 'worst', 'time', ',', 'age', 'wisdom', ',', 'age', 'foolish', ',', 'epoch', 'belief', ',', 'epoch', 'incredul', ',', 'season', 'light', ',', 'season', 'dark', ',', 'spring', 'hope', ',', 'winter', 'despair']\n"
     ]
    }
   ],
   "source": [
    "for word in tokens_without_sw:\n",
    "    print(\"Oroginal: %s, Stem: %s\" % (word, porter.stem(word)))\n",
    "\n",
    "final = [porter.stem(word) for word in tokens_without_sw]\n",
    "\n",
    "print(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precis\n"
     ]
    }
   ],
   "source": [
    "print(porter.stem('precision'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Fortu\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Call, Stemmed: Call\n",
      "Original: Ishmael, Stemmed: Ishmael\n",
      "Original: ., Stemmed: .\n",
      "Original: Some, Stemmed: Some\n",
      "Original: years, Stemmed: year\n",
      "Original: ago—never, Stemmed: ago—never\n",
      "Original: mind, Stemmed: mind\n",
      "Original: long, Stemmed: long\n",
      "Original: precisely—having, Stemmed: precisely—having\n",
      "Original: money, Stemmed: money\n",
      "Original: purse, Stemmed: purse\n",
      "Original: ,, Stemmed: ,\n",
      "Original: particular, Stemmed: particular\n",
      "Original: interest, Stemmed: interest\n",
      "Original: shore, Stemmed: shore\n",
      "Original: ,, Stemmed: ,\n",
      "Original: I, Stemmed: I\n",
      "Original: I, Stemmed: I\n",
      "Original: sail, Stemmed: sail\n",
      "Original: watery, Stemmed: watery\n",
      "Original: part, Stemmed: part\n",
      "Original: world, Stemmed: world\n",
      "Original: ., Stemmed: .\n",
      "Original: It, Stemmed: It\n",
      "Original: I, Stemmed: I\n",
      "Original: driving, Stemmed: driving\n",
      "Original: spleen, Stemmed: spleen\n",
      "Original: regulating, Stemmed: regulating\n",
      "Original: circulation, Stemmed: circulation\n",
      "Original: ., Stemmed: .\n",
      "Original: Whenever, Stemmed: Whenever\n",
      "Original: I, Stemmed: I\n",
      "Original: find, Stemmed: find\n",
      "Original: growing, Stemmed: growing\n",
      "Original: grim, Stemmed: grim\n",
      "Original: mouth, Stemmed: mouth\n",
      "Original: ;, Stemmed: ;\n",
      "Original: damp, Stemmed: damp\n",
      "Original: ,, Stemmed: ,\n",
      "Original: drizzly, Stemmed: drizzly\n",
      "Original: November, Stemmed: November\n",
      "Original: soul, Stemmed: soul\n",
      "Original: ;, Stemmed: ;\n",
      "Original: I, Stemmed: I\n",
      "Original: find, Stemmed: find\n",
      "Original: involuntarily, Stemmed: involuntarily\n",
      "Original: pausing, Stemmed: pausing\n",
      "Original: coffin, Stemmed: coffin\n",
      "Original: warehouses, Stemmed: warehouse\n",
      "Original: ,, Stemmed: ,\n",
      "Original: bringing, Stemmed: bringing\n",
      "Original: rear, Stemmed: rear\n",
      "Original: funeral, Stemmed: funeral\n",
      "Original: I, Stemmed: I\n",
      "Original: meet, Stemmed: meet\n",
      "Original: ;, Stemmed: ;\n",
      "Original: especially, Stemmed: especially\n",
      "Original: hypos, Stemmed: hypo\n",
      "Original: upper, Stemmed: upper\n",
      "Original: hand, Stemmed: hand\n",
      "Original: ,, Stemmed: ,\n",
      "Original: requires, Stemmed: requires\n",
      "Original: strong, Stemmed: strong\n",
      "Original: principle, Stemmed: principle\n",
      "Original: prevent, Stemmed: prevent\n",
      "Original: deliberately, Stemmed: deliberately\n",
      "Original: stepping, Stemmed: stepping\n",
      "Original: street, Stemmed: street\n",
      "Original: ,, Stemmed: ,\n",
      "Original: methodically, Stemmed: methodically\n",
      "Original: knocking, Stemmed: knocking\n",
      "Original: ’, Stemmed: ’\n",
      "Original: hats, Stemmed: hat\n",
      "Original: off—then, Stemmed: off—then\n",
      "Original: ,, Stemmed: ,\n",
      "Original: I, Stemmed: I\n",
      "Original: account, Stemmed: account\n",
      "Original: high, Stemmed: high\n",
      "Original: time, Stemmed: time\n",
      "Original: I, Stemmed: I\n",
      "Original: ., Stemmed: .\n"
     ]
    }
   ],
   "source": [
    "for word in tokens_without_sw:\n",
    "  print(\"Original: %s, Stemmed: %s\" % (word,wordnet_lemmatizer.lemmatize(word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision\n"
     ]
    }
   ],
   "source": [
    "print(wordnet_lemmatizer.lemmatize('precision'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dictionary\n",
      "dictionari\n"
     ]
    }
   ],
   "source": [
    "print(wordnet_lemmatizer.lemmatize('dictionary'))\n",
    "print(porter.stem('dictionary'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Call', 'Call', 'call'), ('me', 'me', 'me'), ('Ishmael', 'Ishmael', 'ishmael'), ('.', '.', '.'), ('Some', 'Some', 'some'), ('years', 'year', 'year'), ('ago—never', 'ago—never', 'ago—nev'), ('mind', 'mind', 'mind'), ('how', 'how', 'how'), ('long', 'long', 'long'), ('precisely—having', 'precisely—having', 'precisely—hav'), ('little', 'little', 'littl'), ('or', 'or', 'or'), ('no', 'no', 'no'), ('money', 'money', 'money'), ('in', 'in', 'in'), ('my', 'my', 'my'), ('purse', 'purse', 'purs'), (',', ',', ','), ('and', 'and', 'and'), ('nothing', 'nothing', 'noth'), ('particular', 'particular', 'particular'), ('to', 'to', 'to'), ('interest', 'interest', 'interest'), ('me', 'me', 'me'), ('on', 'on', 'on'), ('shore', 'shore', 'shore'), (',', ',', ','), ('I', 'I', 'i'), ('thought', 'thought', 'thought'), ('I', 'I', 'i'), ('would', 'would', 'would'), ('sail', 'sail', 'sail'), ('about', 'about', 'about'), ('a', 'a', 'a'), ('little', 'little', 'littl'), ('and', 'and', 'and'), ('see', 'see', 'see'), ('the', 'the', 'the'), ('watery', 'watery', 'wateri'), ('part', 'part', 'part'), ('of', 'of', 'of'), ('the', 'the', 'the'), ('world', 'world', 'world'), ('.', '.', '.'), ('It', 'It', 'it'), ('is', 'is', 'is'), ('a', 'a', 'a'), ('way', 'way', 'way'), ('I', 'I', 'i'), ('have', 'have', 'have'), ('of', 'of', 'of'), ('driving', 'driving', 'drive'), ('off', 'off', 'off'), ('the', 'the', 'the'), ('spleen', 'spleen', 'spleen'), ('and', 'and', 'and'), ('regulating', 'regulating', 'regul'), ('the', 'the', 'the'), ('circulation', 'circulation', 'circul'), ('.', '.', '.'), ('Whenever', 'Whenever', 'whenev'), ('I', 'I', 'i'), ('find', 'find', 'find'), ('myself', 'myself', 'myself'), ('growing', 'growing', 'grow'), ('grim', 'grim', 'grim'), ('about', 'about', 'about'), ('the', 'the', 'the'), ('mouth', 'mouth', 'mouth'), (';', ';', ';'), ('whenever', 'whenever', 'whenev'), ('it', 'it', 'it'), ('is', 'is', 'is'), ('a', 'a', 'a'), ('damp', 'damp', 'damp'), (',', ',', ','), ('drizzly', 'drizzly', 'drizzli'), ('November', 'November', 'novemb'), ('in', 'in', 'in'), ('my', 'my', 'my'), ('soul', 'soul', 'soul'), (';', ';', ';'), ('whenever', 'whenever', 'whenev'), ('I', 'I', 'i'), ('find', 'find', 'find'), ('myself', 'myself', 'myself'), ('involuntarily', 'involuntarily', 'involuntarili'), ('pausing', 'pausing', 'paus'), ('before', 'before', 'befor'), ('coffin', 'coffin', 'coffin'), ('warehouses', 'warehouse', 'warehous'), (',', ',', ','), ('and', 'and', 'and'), ('bringing', 'bringing', 'bring'), ('up', 'up', 'up'), ('the', 'the', 'the'), ('rear', 'rear', 'rear'), ('of', 'of', 'of'), ('every', 'every', 'everi'), ('funeral', 'funeral', 'funer'), ('I', 'I', 'i'), ('meet', 'meet', 'meet'), (';', ';', ';'), ('and', 'and', 'and'), ('especially', 'especially', 'especi'), ('whenever', 'whenever', 'whenev'), ('my', 'my', 'my'), ('hypos', 'hypo', 'hypo'), ('get', 'get', 'get'), ('such', 'such', 'such'), ('an', 'an', 'an'), ('upper', 'upper', 'upper'), ('hand', 'hand', 'hand'), ('of', 'of', 'of'), ('me', 'me', 'me'), (',', ',', ','), ('that', 'that', 'that'), ('it', 'it', 'it'), ('requires', 'requires', 'requir'), ('a', 'a', 'a'), ('strong', 'strong', 'strong'), ('moral', 'moral', 'moral'), ('principle', 'principle', 'principl'), ('to', 'to', 'to'), ('prevent', 'prevent', 'prevent'), ('me', 'me', 'me'), ('from', 'from', 'from'), ('deliberately', 'deliberately', 'deliber'), ('stepping', 'stepping', 'step'), ('into', 'into', 'into'), ('the', 'the', 'the'), ('street', 'street', 'street'), (',', ',', ','), ('and', 'and', 'and'), ('methodically', 'methodically', 'method'), ('knocking', 'knocking', 'knock'), ('people', 'people', 'peopl'), ('’', '’', '’'), ('s', 's', 's'), ('hats', 'hat', 'hat'), ('off—then', 'off—then', 'off—then'), (',', ',', ','), ('I', 'I', 'i'), ('account', 'account', 'account'), ('it', 'it', 'it'), ('high', 'high', 'high'), ('time', 'time', 'time'), ('to', 'to', 'to'), ('get', 'get', 'get'), ('to', 'to', 'to'), ('sea', 'sea', 'sea'), ('as', 'a', 'as'), ('soon', 'soon', 'soon'), ('as', 'a', 'as'), ('I', 'I', 'i'), ('can', 'can', 'can'), ('.', '.', '.')]\n"
     ]
    }
   ],
   "source": [
    "comparison = [(word, wordnet_lemmatizer.lemmatize(word), porter.stem(word)) for word in word_tokens]\n",
    "print(comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
