{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Give four ideas for introducing agents in a search or a recommender system and what specific metrics you would use to show their effectiveness. Limit your response to 1 page. [4 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Personalized Recommendation Agent\n",
    "  - Description: This agent will recommend items based on the user's past interactions with the system. It will use collaborative filtering to recommend items that similar users have interacted with.\n",
    "  - Effectiveness Metrics:\n",
    "    - Precision@k: The proportion of recommended items that are relevant to the user in the top k recommendations.\n",
    "    - Recall@k: The proportion of relevant items that are recommended in the top k recommendations.\n",
    "    - Mean Average Precision: The average precision at each relevant item's rank.\n",
    "2. Exploration-Focused Agent\n",
    "  - Description: An agent using Reinforcement Learning to learn the balance between exploration and exploitation. It will recommend items that the user has not interacted with but are likely to be relevant.\n",
    "  - Effectiveness Metrics:\n",
    "    - Diversity Score: The diversity of items recommended to the user. Measured by the number of unique items recommended.\n",
    "    - User Engagement: The user's interaction with the recommended items. Measured by the click-through rate or dwell time.\n",
    "    - Long-Term Retentuion: The user's retention rate over time after interacting with the recommended items.\n",
    "3. Conversational Search Agent\n",
    "  - Description: An agent that uses Natural Language Processing (NLP) to understand user queries and provide conversational responses. It will engage in a dialogue with the user to refine the search query and provide more relevant results.\n",
    "  - Effectiveness Metrics:\n",
    "    - User Satisfaction: The user's satisfaction with the search results and the conversational experience. Measured by user feedback or ratings.\n",
    "    - Task Completion Rate: The proportion of user queries that are successfully resolved by the agent.\n",
    "    - Response Time: The time taken by the agent to respond to user queries and provide relevant results.\n",
    "4. Context-Aware Agent\n",
    "  - Description: An agent that considers the user's context, such as location, time, and device, to provide personalized recommendations. It will adapt the recommendations based on the user's current situation.\n",
    "  - Effectiveness Metrics:\n",
    "    - Contextual Relevance: The relevance of the recommended items to the user's context. Measured by user feedback or relevance scores.\n",
    "    - User Engagement: The user's interaction with the recommended items based on the context. Measured by the click-through rate or conversion rate.\n",
    "    - Personalization Accuracy: The accuracy of the agent in adapting recommendations to the user's context. Measured by the proportion of contextually relevant recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Personalization requires learning on top of filtering. These learning can be explicit or implicit. Explain in a sentence or two what each of these mean. Then given an example for each of these to show how personalization systems can function with them. Limit your response to half a page. [2 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Explicit Learning\n",
    "  - Definition: Explicit learning involves directly obtaining user preferences or feedback through deliberate user actions, such as ratings, likes, or filling out a preference survey.\n",
    "  - Example: A movie recommendation system where users rate films on a scale of 1 to 5, enabling the system to tailor future recommendations based on these explicit ratings.\n",
    "2. Implicit Learning\n",
    "  - Definition: Implicit learning involves inferring user preferences or feedback from user behavior or interactions with the system, such as clicks, views, purchases, or dwell time.\n",
    "  - Example: An e-commerce platform that tracks user browsing history and purchase behavior to recommend products based on the user's implicit preferences and interests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have access to log data for an interactive (search and/or recommender) system, and asked to use that to build user models. What sort of behavioral data/signals would you use for building such models? Limit your response to half a page. [2 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build user models from log data in an interactive search or recommender system, I would use the following behavioral data/signals:\n",
    "- Click Data: User clicks on search results or recommended items to understand user preferences and relevance.\n",
    "- Query Data: User search queries to capture user intent and interests.\n",
    "- Dwell Time: The time spent by the user on search results or recommended items to measure user engagement and relevance.\n",
    "- Purchase History: User purchase behavior to understand user preferences and buying patterns.\n",
    "- Interaction Patterns: User interactions with the system, such as views, likes, or shares, to capture user interests and preferences.\n",
    "- Session Data: User session information, such as start time, end time, and duration, to analyze user behavior over time.\n",
    "- Rating Data: User ratings or feedback on items to capture user preferences and satisfaction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report your project progress in no more than half a page. What have you accomplished? Where are you now? What is your plan to get it done in another week or so? [2 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have finalized our collection selection and are currently in the process of storing it on the class server. A presentation template has also been created to organize our work. Once the collection process is complete, we will index the data and start the system instance. Over the next week, we plan to finish indexing, test the system for performance, and finalize our presentation with results and insights, ensuring we stay on track to meet the deadline."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
